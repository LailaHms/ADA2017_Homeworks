{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 2 : Data Collection and Description\n",
    "------\n",
    "In this notebook we are going to review everything that was done so far in the project and evaluate what the remaining tasks are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "\n",
    "\n",
    "## 1.  Identifying Relevant Tweets\n",
    "-----\n",
    "\n",
    "### 1.1 Hashtags as Key Elements for Searching\n",
    "\n",
    "On twitter the Hashtags are mainly during events. In our case it is the perfect tool to evaluate the awareness across the world. It is very convenient because it is often specifically related to one event and tends to be in english even though the rest of the tweet is in a different language. In order to find all the tweets related to an event, we needed to find as many hashtags which were related and in as many languages as possible.  \n",
    "\n",
    "### 1.2 Selection of Hashtags "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "\n",
    "## 2.  Tweets Acquisition\n",
    "We had originally planned to use the twitter dataset that was given in the course. Unfortunatelly it was containing only 10% of the tweets in a given time period and wasn't including any information on the location of the user nor the user profile. Because of this we decided to go get the tweets about specific events by ourselves. \n",
    "\n",
    "------\n",
    "### 2.1 Twitter API \n",
    "Our initial idea was to get the information we needed with the Twitter API, but there again we encountered several problems : \n",
    "\n",
    "- The **Rate Limit** of the Twitter API :  It would have taken a lot of time to get the tweets of a specific event, but we were ready to wait and launch the code on several computers (or on clusters)\n",
    "- The **Search Query** limitations : After designing a code that would allow us to get the tweets by searching specific hashtags over a time interval, we discovered a huge limitation : tweets can only we searched with the API if they are *less than one week old*. \n",
    "\n",
    "So we have to discard the idea to use the Twitter API.\n",
    "\n",
    "------\n",
    "### 2.2 Scrapping Manually the Tweets \n",
    "Fortunatelly the twitter html interface (the website) allows us to search for any query on anytime interval. So we decided get the data by scraping directly the website. For that we use a browser that doesn't have a user interface **PhantomJS** and **Selenium** a python package that allows us to load urls in this browser and scroll down the search page in order to load results. Once loaded the use **Beautifull Soup 4** with the parser **LXML** To get every tweets of the page.\n",
    "\n",
    "This was done using one script : [`tweet_acquisiton.py`](ADA2017_Homeworks/Project/TweetAcquisition/tweet_acquisition.py). \n",
    "For each event a new folder is created (for example here `Nigeria_1`). The logs of the tweet acquisition has been saved in this folder with an obvious name (Here `Nigeria_1.log`). Here is an example of the start of the log file : \n",
    "\n",
    "-----\n",
    "```javascript\n",
    "------------------------------------------- ACQUISITION PARAMETERS -------------------------------------------\n",
    "Started at : 2017-11-27 10:10:47.485905\n",
    "Tweets saved in ./Nigeria_1/\n",
    "Searching from 2016-01-29 to 2016-02-06\n",
    "Hastags used : ['Dalori', 'Dalorilivesmatter', 'Nigeria', 'BokoHaram', 'Bokoharam', 'bokoharam', 'Borno', 'StopBokoHaram', 'PrayForNigeria']\n",
    "------------------------------------------- STARTING ACQUISITION -------------------------------------------\n",
    "1 - Tweets : 2772 - Total : 2772 - Date : 2016-02-05 07:39:06 - Elapsed Time : 810.799 s - Delay : 810.799 s - Rate : 3.419 tw/s - Executed at 2017-11-27 10:24:20.470199\n",
    "     + First Tweet Time : 2016-02-05 22:11:24\n",
    "     + Last Tweet Time : 2016-02-05 07:39:06\n",
    "```\n",
    "\n",
    "------\n",
    "The query url is created using the list of hashtags specified inside the script. The explanations on how to use the scripts are in the [`README.md`](ADA2017_Homeworks/Project/TweetAcquisition/README.md) file.\n",
    "\n",
    "\n",
    "The tweets are acquired by segments : we scroll 500 times the page before parsing the html and saving a pickle containing the Raw data. Each pickle contains an average of 7000 tweets.  We show here an example of the structure of the dataframe acquired :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[@FitzMP, #Biafrans, #Nigeria, #TyrantBuhari]</td>\n",
       "      <td>695731474243440640</td>\n",
       "      <td>en</td>\n",
       "      <td>@FitzMP,We #Biafrans have died enough, we don’...</td>\n",
       "      <td>1454710284</td>\n",
       "      <td>354778701</td>\n",
       "      <td>EmekaGift</td>\n",
       "      <td>2016-02-05 22:11:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[#Nigeria, http://bit.ly/1SR2k89 ]</td>\n",
       "      <td>695758765627281408</td>\n",
       "      <td>es</td>\n",
       "      <td>A más de dos años de que comenzó la crisis, ¿q...</td>\n",
       "      <td>1454716790</td>\n",
       "      <td>57683930</td>\n",
       "      <td>MSF_Mexico</td>\n",
       "      <td>2016-02-05 23:59:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[#PrayForNigeria]</td>\n",
       "      <td>695758763517730816</td>\n",
       "      <td>en</td>\n",
       "      <td>I wish I was a little kid again, where all I h...</td>\n",
       "      <td>1454716790</td>\n",
       "      <td>518819812</td>\n",
       "      <td>allthingselliej</td>\n",
       "      <td>2016-02-05 23:59:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[#Nigeria, http://bit.ly/1odNc9y , #VOA]</td>\n",
       "      <td>695758537289367552</td>\n",
       "      <td>en</td>\n",
       "      <td>#Nigeria E-readers Help Thousands in Africa Le...</td>\n",
       "      <td>1454716736</td>\n",
       "      <td>2468196914</td>\n",
       "      <td>Vincecob</td>\n",
       "      <td>2016-02-05 23:58:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        hashtags                  id language  \\\n",
       "0  [@FitzMP, #Biafrans, #Nigeria, #TyrantBuhari]  695731474243440640       en   \n",
       "1             [#Nigeria, http://bit.ly/1SR2k89 ]  695758765627281408       es   \n",
       "2                              [#PrayForNigeria]  695758763517730816       en   \n",
       "3       [#Nigeria, http://bit.ly/1odNc9y , #VOA]  695758537289367552       en   \n",
       "\n",
       "                                                text  time_stamp     user_id  \\\n",
       "0  @FitzMP,We #Biafrans have died enough, we don’...  1454710284   354778701   \n",
       "1  A más de dos años de que comenzó la crisis, ¿q...  1454716790    57683930   \n",
       "2  I wish I was a little kid again, where all I h...  1454716790   518819812   \n",
       "3  #Nigeria E-readers Help Thousands in Africa Le...  1454716736  2468196914   \n",
       "\n",
       "         user_name                date  \n",
       "0        EmekaGift 2016-02-05 22:11:24  \n",
       "1       MSF_Mexico 2016-02-05 23:59:50  \n",
       "2  allthingselliej 2016-02-05 23:59:50  \n",
       "3         Vincecob 2016-02-05 23:58:56  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle.load(open('TweetAcquisition/Nigeria_1/Tweets_1.pickle', 'rb'))\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have scrapped as many information as possible from the html page of the search query, bit we still miss the most important thing : the location of the tweet.\n",
    "\n",
    "------\n",
    "### 2.3 Scrapping the location of the tweets \n",
    "From each tweet we take the `user_name` field and we go to the user profile to get the location information that the user has written on his profile. \n",
    "The function that does that is : [`location_acquisiton.py`](ADA2017_Homeworks/Project/TweetAcquisition/location_acquisiton.py). As we don't need to scroll down the page we directly use the **requests** python package combined with **Beautiful Soup 4** and **LXML**. As the code is very slow, we launch several times the process in parrallel in order to get the tweets at the same rate. \n",
    "\n",
    "In the follwing we display the head of the *Located* version of the pickled dataframe. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[@FitzMP, #Biafrans, #Nigeria, #TyrantBuhari]</td>\n",
       "      <td>695731474243440640</td>\n",
       "      <td>en</td>\n",
       "      <td>@FitzMP,We #Biafrans have died enough, we don’...</td>\n",
       "      <td>1454710284</td>\n",
       "      <td>354778701</td>\n",
       "      <td>EmekaGift</td>\n",
       "      <td>2016-02-05 22:11:24</td>\n",
       "      <td>[www.radiobiafra.co]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[#Nigeria, http://bit.ly/1SR2k89 ]</td>\n",
       "      <td>695758765627281408</td>\n",
       "      <td>es</td>\n",
       "      <td>A más de dos años de que comenzó la crisis, ¿q...</td>\n",
       "      <td>1454716790</td>\n",
       "      <td>57683930</td>\n",
       "      <td>MSF_Mexico</td>\n",
       "      <td>2016-02-05 23:59:50</td>\n",
       "      <td>[Ciudad, de, Mexico]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[#PrayForNigeria]</td>\n",
       "      <td>695758763517730816</td>\n",
       "      <td>en</td>\n",
       "      <td>I wish I was a little kid again, where all I h...</td>\n",
       "      <td>1454716790</td>\n",
       "      <td>518819812</td>\n",
       "      <td>allthingselliej</td>\n",
       "      <td>2016-02-05 23:59:50</td>\n",
       "      <td>[SomewhereOnlyWeKnow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[#Nigeria, http://bit.ly/1odNc9y , #VOA]</td>\n",
       "      <td>695758537289367552</td>\n",
       "      <td>en</td>\n",
       "      <td>#Nigeria E-readers Help Thousands in Africa Le...</td>\n",
       "      <td>1454716736</td>\n",
       "      <td>2468196914</td>\n",
       "      <td>Vincecob</td>\n",
       "      <td>2016-02-05 23:58:56</td>\n",
       "      <td>[Brussels,, Belgium]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        hashtags                  id language  \\\n",
       "0  [@FitzMP, #Biafrans, #Nigeria, #TyrantBuhari]  695731474243440640       en   \n",
       "1             [#Nigeria, http://bit.ly/1SR2k89 ]  695758765627281408       es   \n",
       "2                              [#PrayForNigeria]  695758763517730816       en   \n",
       "3       [#Nigeria, http://bit.ly/1odNc9y , #VOA]  695758537289367552       en   \n",
       "\n",
       "                                                text  time_stamp     user_id  \\\n",
       "0  @FitzMP,We #Biafrans have died enough, we don’...  1454710284   354778701   \n",
       "1  A más de dos años de que comenzó la crisis, ¿q...  1454716790    57683930   \n",
       "2  I wish I was a little kid again, where all I h...  1454716790   518819812   \n",
       "3  #Nigeria E-readers Help Thousands in Africa Le...  1454716736  2468196914   \n",
       "\n",
       "         user_name                date               location  \n",
       "0        EmekaGift 2016-02-05 22:11:24   [www.radiobiafra.co]  \n",
       "1       MSF_Mexico 2016-02-05 23:59:50   [Ciudad, de, Mexico]  \n",
       "2  allthingselliej 2016-02-05 23:59:50  [SomewhereOnlyWeKnow]  \n",
       "3         Vincecob 2016-02-05 23:58:56   [Brussels,, Belgium]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pickle.load(open('TweetAcquisition/Nigeria_1/Located_Tweets_1.pickle', 'rb'))\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the raw location information for each event. We need to geocode it to the associated country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "## 3.  Geocoding the tweets\n",
    "\n",
    "------\n",
    "### 3.1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 4.  Enriching the Data\n",
    "------\n",
    "### 4.1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 5. Data Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 6. Critical Assessment\n",
    "\n",
    "- Fact that twitter is biased by nature \n",
    "- Ideally we should have scrapped data from different social media\n",
    "- Locations are never to be perfect, the location information is not objective. \n",
    "- Could have used Google API for example, but it is limited in the number of queries, and I won't be perfect either because usually google maps uses contextual infomation to find the location you are looking for. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "## 7. What's next ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ADA]",
   "language": "python",
   "name": "conda-env-ADA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
