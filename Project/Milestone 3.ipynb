{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3 - Report\n",
    "------\n",
    "In this notebook we are going to summarize what was done in Milestone 2 and explain all that was done for the final Milestone. The focus at this point of the project was placed on constructing the awareness model using our different metrics and the final datastory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import folium\n",
    "import branca\n",
    "import jenkspy\n",
    "import pickle\n",
    "import unicodedata\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Abstract\n",
    "\n",
    "*What's the motivation behind your project? A 150 word description of the project idea, goals, dataset used. What story you would like to tell and why?*\n",
    "\n",
    "Major events happen on a regular basis all around the world, some involving high number of casualties but the resulting reaction on the international scale is often far from proportional. Most of the time the largest reaction comes from the place where the incident occurred or places which are closeby. The objective would be to create an awareness map, and determine why people react to an event. From that we would attempt to define an awareness metric. We want to see how factors other than physical proximity come into play such as country, culture, language, religion. With this we could determine which country has the highest level of international awareness. The project would require the Twitter API to acquire hashtag specific tweets with geolocation and therefore measure the awareness and reactions of different communities to a given event. GDELT would be used to recover standardised information regarding different events.\n",
    "____\n",
    "____\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recapitulation of Milestone 2\n",
    "\n",
    "To recap what was done in the previous milestone, here we present a brief summary of the previous notebook which can be found here **(TODO : mettre le lien)**. \n",
    "\n",
    "____\n",
    "\n",
    "## 1.1 Tweet Acquisition\n",
    "A lot of time was spent acquiring the Tweets for two main reasons : \n",
    "- The Twitter dump did not contain the geolocations of the tweets or the users and only containecd 10% of all tweets for a given period. Given that users to not necessarily give their location we wanted to avoid cases where we would not have enough overall located tweets. \n",
    "- The Twitter API does not permit the recovery of tweets which are over 1 week old when searching for tweets with a given hashtag around a specific date. \n",
    "\n",
    "That is why a significant amount of time was put into recovering the tweets through webscraping using phantom js with random scrolling time and random breaks to avoid being blocked by Twitter.\n",
    "\n",
    "The tweets were acquired based on their hashtags, all the while making sure to have a wide range of hashtags in different languages. \n",
    "\n",
    "**TODO : put the link towards the file containing all the hashtags**\n",
    "\n",
    "____\n",
    "\n",
    "## 1.2. Tweet Geolocalisation\n",
    "\n",
    "Once the tweets were recovered we only kept those for which we had either the geolocalisation of the tweets itself or of the user. As the locations are manually input, they are not standardized and the corresponding location needed to be determined. \n",
    "\n",
    "The first step was therefore to format the strings by removing all special characters as setting everything to lower case for example.  Afterwards, we created multiple mappings which were used in the order presented as they represent the confidence in the given method : \n",
    "- A country mapper which uses multiple variations of the country name (different spellings and languages) to determine the country it corresponds to with the given ISO2 code\n",
    "- A capital mapper which maps the capital of a country to the ISO2 code\n",
    "- A first city mapper where duplicates were removed as there are multiple cities in the world with the same name (example : Torronto in Canada, the US and Australia). \n",
    "- A final city mapper with all the cities of all the countries in the world using the database provided here **(TODO : mettre le lien)**\n",
    "\n",
    "** TODO : put the image of the bird with the number of tweets** \n",
    "\n",
    "\n",
    "## 1.3. Visualization of the Reaction For An Event\n",
    "\n",
    "We then observed for one of the selected events the number of related tweets on a Chloropleth map. This helped us note certain issues in the mappings (high number of tweets in Antarctica for example). \n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "## 1.4. Enriching the Data \n",
    "\n",
    "To create our awareness model we wanted to recover information which could be used to determine a sort of distance between the different countries, that is why we recovered for all countries: \n",
    "- area\n",
    "- ISO2\n",
    "- ISO3\n",
    "- languages\n",
    "- border countries\n",
    "- latitude and longitude\n",
    "- language_codes\n",
    "- Internet users\n",
    "- population\n",
    "- GDP\n",
    "- GDP per capita\n",
    "- religions\n",
    "- government types\n",
    "- population in poverty\n",
    "- unemployment rate\n",
    "\n",
    "As you can see, we have more features than we had originally presented in Milestone 2. That's because we realized that one of the datasets we used had a lot more (and more complete) information that was of our interest. After all, the 4 datasets that we were using originally ended up being just two, which are these:\n",
    "\n",
    "- Dataset 1: https://github.com/mledoze/countries\n",
    "- Dataset 2: https://github.com/opendatajson/factbook.json\n",
    "\n",
    "To see all the detailed process of the extraction of the data see \"Data enriching.ipynb\".\n",
    "____\n",
    "____\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "# 2. Improving the Mappings\n",
    "\n",
    "One main issue with the mapping up until now is that there were redundancies which were not correctly handled. At the time of Milestone 2 we would just go through the complete mapping sequentially and stop at the first match. As there were duplicates there was no guarantee that the city found was the most coherent. That is why we corrected the mapping to take into account the population of the different cities which was also provided in the GeoNames database http://download.geonames.org/export/dump/. Therefore when there are multiple cities with the same name in different countries, we only keep the city with the largest population as it would be the most probable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also replaced our intermediate city mapping with a mapping containing the top 20'000 cities in the world (and therefore the most probable). With appoximately 200 countries this corresponds to around 100 cities per country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Metrics For the Awareness Model\n",
    "\n",
    "To create our model we originally planned to construct a graph linking all countries where the weights of the segments would represent the proximity between countries in terms of awareness to major events. \n",
    "\n",
    "For that we used the dataset containing all the information regarding the countries and looked to give numeric values to all the different categories mentioned previously and a few new ones: \n",
    "\n",
    "1. Languages\n",
    "2. Governments \n",
    "3. Distances between countries :\n",
    "    - Birds eye view distances \n",
    "    - Hop matrix : the number of countries which separate two given countries (**TODO : noter quil y a le souci des distances a traverser au sein des pays qui n'est pas pris en compte, exemple de la Finlande a la Chine qui passe uniquement par la russie**). \n",
    "    - Normalized Adj matrix : a matrix which gives the neighboring countries with a normalizing factor to account for multiple countries on the border\n",
    "    - Flight routes between countries\n",
    "4. Religion\n",
    "5. Population, Area, GDP, Internet Users etc...\n",
    "\n",
    "\n",
    "What needed to be taken into account here is that we have many variables which are categoric. Therefore we needed to find a way to attribute numeric values in order to construct the final graph.\n",
    "\n",
    "Remark : most of the information was extracted from the CIA factbook as it is a complete and realiable source.  **TODO : put the link**\n",
    "\n",
    "**TODO / REMARQUE A GARDER EN TETE POUR LA CONCLUSION AU PIRE : voir si le fait que le pays soit très grand avec une grande population qui peut diminuer l'intérêt par rapport à ce qui se passe ailleurs dans le monde**\n",
    "\n",
    "____\n",
    "\n",
    "## 3.1. Languages\n",
    "\n",
    "Languages are representative of culture and most of the time, countries which speak the same language have a given proximity. That is why this metric was used to create the graph. \n",
    "\n",
    "Two main possibilities presented themselves :\n",
    "- binary : if two countries have the same official language then they are linked\n",
    "- more informed : some languages are similar in the sense of understanding the other language, learning it, etc. That is why we wanted to take into account Linguistic distances. Unfortunately this is a current research topic and there is no database which gives the Linguistic distances between all the official languages of all countries. Certain databases exist linking English to other languages but this is not sufficient for our application. That is why we decided to use another metric, albeit more abstact, which is to say the phylogenetic trees linking languages together. \n",
    "\n",
    "\n",
    "Using the phylogenetic trees taken here (**TODO insert nice link**) http://glottolog.org/glottolog/family, we were able to construct a distance metric and compute the distances between all languages as can be seen below. The notebook handling this can be found here (**TODO : mettre le lien du notebook**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO METTRE LA MATRICE & HEATMAP DE DISTANCE ENTRE LES LANGUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this language distance matrix we were able to compute a standardized distance between all countries. \n",
    "\n",
    "The idea is the following :\n",
    "- if countries have an official language in common, set the distance to 0\n",
    "- else get the distances between the official languages and compute the average of the non infinite distances. \n",
    "- else set the distance to inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO METTRE LA MATRICE DISTANCE / HEATMAP ENTRE LES PAYS SELON LA LANGUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with this type of distance is that it takes discrete values which don't account for the actual distance between the different languages in terms of comprehension, facility to learn the other language etc.. For example the distance between French and a dialect ....\n",
    "**TODO : afficher deux valeurs de distance similaires mais qui ne sont pas représentatifs**\n",
    "\n",
    "Results more representative of the reality of the situation could have been obtained had we had not only the phylogenetic links between the languages but the moment that the a new language appeared from a mother language. Incoroporating this time component would have given a more precise approximation, assuming that languages evolve at similar rates and that once the new language has emerged that there is minimal contact / influence from the mother or any sister languages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.2. Governments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of government is also a good representative of the people's perception to worldwide events. People of different countries with the same government type will be influenced in a similar way. \n",
    "\n",
    "After getting the list of all the government types (see \"Data enriching.ipynb\" for more details on how we got them) we have to convert them to a numeric scale with a meaning.\n",
    "\n",
    "First, we start by dividing all the government types in three groups and assigning them numerical values -1, 0 and 1. These are the resulting groups:\n",
    "- Group 1:\n",
    "    - 'parliamentary democracy'\n",
    "    - 'parliamentary republic'\n",
    "    - 'federal republic'\n",
    "    - 'federation of monarchies'\n",
    "    - 'semi-presidential republic'\n",
    "    - 'semi-presidential federation'\n",
    "- Group 2: \n",
    "    - 'non-self-governing overseas territory'\n",
    "    - 'in transition'\n",
    "    - 'unknown'\n",
    "- Group 3: \n",
    "    - 'presidential republic'\n",
    "    - 'presidential democracy'\n",
    "    - 'monarchy'\n",
    "    - 'theocratic republic'\n",
    "    - 'communist state'\n",
    "    - 'absolute monarchy'\n",
    "\n",
    "As our criteria to group the government types, we used the variable of the power that the leaders of the government have. Coutries where the leader has a lot of power go in group 3 and will be assigned to the value of 1, the others in group 1 and they will be assigned the value -1. For the non well defined government types, we placed them at the center of the scale with the value of 0.\n",
    "\n",
    "Here is the actual implementation (full code on \"Data enriching.ipynb\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>gov_type</th>\n",
       "      <th>gov_type_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aruba</th>\n",
       "      <td>parliamentary democracy</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>presidential republic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>presidential republic</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anguilla</th>\n",
       "      <td>parliamentary democracy</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Åland Islands</th>\n",
       "      <td>unknown</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              gov_type gov_type_num\n",
       "                                                   \n",
       "name                                               \n",
       "Aruba          parliamentary democracy         -1.0\n",
       "Afghanistan      presidential republic          1.0\n",
       "Angola           presidential republic          1.0\n",
       "Anguilla       parliamentary democracy         -1.0\n",
       "Åland Islands                  unknown          0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataframe\n",
    "data = pd.read_pickle('./DataEnriching/data.pickle')\n",
    "\n",
    "# Defining the three groups\n",
    "gov_type_array = [['parliamentary democracy', 'parliamentary republic', 'federal republic', 'federation of monarchies',\n",
    "                   'semi-presidential republic', 'semi-presidential federation'],\n",
    "                  ['non-self-governing overseas territory', 'in transition', 'unknown'],\n",
    "                  ['presidential republic', 'presidential democracy', 'monarchy', 'theocratic republic', 'communist state',\n",
    "                   'absolute monarchy']]\n",
    "\n",
    "# Creating the mapping dictionary\n",
    "mapping_gov_type=dict()\n",
    "for i, gov_group in enumerate(gov_type_array):\n",
    "    for gov in gov_group:\n",
    "        if i==0:\n",
    "            mapping_gov_type.update({gov: -1})\n",
    "        elif i==1:\n",
    "            mapping_gov_type.update({gov: 0})\n",
    "        else:\n",
    "            mapping_gov_type.update({gov: 1})\n",
    "\n",
    "# Mapping gov_type values to their numerical value (1, 0, -1)\n",
    "data['gov_type_num'] = data.gov_type.map(mapping_gov_type)\n",
    "data[['gov_type', 'gov_type_num']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compute the distance metric between government types, the numeric government type will be used. The distance metric will be defined by the absolute value of the subtraction between the values of each pair of countries. That way, we end up with a symetric metric with possible values of 0, 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the dataframe and setting ISO2 as index (as it will be the useful country code)\n",
    "data = pd.read_pickle(os.path.abspath(os.path.join(os.getcwd() + '\\DataEnriching\\data.pickle')))\n",
    "data.reset_index(inplace=True)\n",
    "data.set_index('ISO2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AW</th>\n",
       "      <th>AF</th>\n",
       "      <th>AO</th>\n",
       "      <th>AI</th>\n",
       "      <th>AX</th>\n",
       "      <th>AL</th>\n",
       "      <th>AD</th>\n",
       "      <th>AE</th>\n",
       "      <th>AR</th>\n",
       "      <th>AM</th>\n",
       "      <th>...</th>\n",
       "      <th>VG</th>\n",
       "      <th>VI</th>\n",
       "      <th>VN</th>\n",
       "      <th>VU</th>\n",
       "      <th>WF</th>\n",
       "      <th>WS</th>\n",
       "      <th>YE</th>\n",
       "      <th>ZA</th>\n",
       "      <th>ZM</th>\n",
       "      <th>ZW</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISO2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AW</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AX</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AM</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 248 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AW   AF   AO   AI   AX   AL   AD   AE   AR   AM ...    VG   VI   VN  \\\n",
       "ISO2                                                   ...                   \n",
       "AW    0.0  2.0  2.0  0.0  1.0  0.0  0.0  0.0  2.0  2.0 ...   0.0  2.0  2.0   \n",
       "AF    2.0  0.0  0.0  2.0  1.0  2.0  2.0  2.0  0.0  0.0 ...   2.0  0.0  0.0   \n",
       "AO    2.0  0.0  0.0  2.0  1.0  2.0  2.0  2.0  0.0  0.0 ...   2.0  0.0  0.0   \n",
       "AI    0.0  2.0  2.0  0.0  1.0  0.0  0.0  0.0  2.0  2.0 ...   0.0  2.0  2.0   \n",
       "AX    1.0  1.0  1.0  1.0  0.0  1.0  1.0  1.0  1.0  1.0 ...   1.0  1.0  1.0   \n",
       "AL    0.0  2.0  2.0  0.0  1.0  0.0  0.0  0.0  2.0  2.0 ...   0.0  2.0  2.0   \n",
       "AD    0.0  2.0  2.0  0.0  1.0  0.0  0.0  0.0  2.0  2.0 ...   0.0  2.0  2.0   \n",
       "AE    0.0  2.0  2.0  0.0  1.0  0.0  0.0  0.0  2.0  2.0 ...   0.0  2.0  2.0   \n",
       "AR    2.0  0.0  0.0  2.0  1.0  2.0  2.0  2.0  0.0  0.0 ...   2.0  0.0  0.0   \n",
       "AM    2.0  0.0  0.0  2.0  1.0  2.0  2.0  2.0  0.0  0.0 ...   2.0  0.0  0.0   \n",
       "\n",
       "       VU   WF   WS   YE   ZA   ZM   ZW  \n",
       "ISO2                                     \n",
       "AW    0.0  0.0  0.0  1.0  0.0  2.0  2.0  \n",
       "AF    2.0  2.0  2.0  1.0  2.0  0.0  0.0  \n",
       "AO    2.0  2.0  2.0  1.0  2.0  0.0  0.0  \n",
       "AI    0.0  0.0  0.0  1.0  0.0  2.0  2.0  \n",
       "AX    1.0  1.0  1.0  0.0  1.0  1.0  1.0  \n",
       "AL    0.0  0.0  0.0  1.0  0.0  2.0  2.0  \n",
       "AD    0.0  0.0  0.0  1.0  0.0  2.0  2.0  \n",
       "AE    0.0  0.0  0.0  1.0  0.0  2.0  2.0  \n",
       "AR    2.0  2.0  2.0  1.0  2.0  0.0  0.0  \n",
       "AM    2.0  2.0  2.0  1.0  2.0  0.0  0.0  \n",
       "\n",
       "[10 rows x 248 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting numeric government type column\n",
    "gov_type_df = data[['gov_type_num']]\n",
    "\n",
    "# Creating the matrix with the distances\n",
    "gov_distance_df = pd.DataFrame(columns=gov_type_df.index.tolist())\n",
    "\n",
    "for country1, value1 in zip(gov_type_df.index.tolist(), gov_type_df['gov_type_num']):\n",
    "    row = []\n",
    "    for country1, value2 in zip(gov_type_df.index.tolist(), gov_type_df['gov_type_num']):\n",
    "        row.append(abs(value1-value2))\n",
    "    \n",
    "    \n",
    "    dictionary = dict(zip(data.index.tolist(), row))\n",
    "    gov_distance_df = gov_distance_df.append(dictionary, ignore_index=True)\n",
    "    \n",
    "gov_distance_df.index = gov_type_df.index\n",
    "gov_distance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.3. Distances \n",
    "\n",
    "Distance tends to play an important role in determining people's interest regarding a specific event. But there are several types of distances which can be considered when speaking of countries. \n",
    "\n",
    "The first and most evident is the **birds-eye-view distance** between the countries. This is computed based on the positions of the center of each country. But this is not enough. Take for example the US and Canada, the distance between the center of thees two countries is much larger than the distance between France and any of its neighboring countries. \n",
    "\n",
    "So what else could we consider to have a more representative representation of distance between the different countries? We came up with three other distance metrics which combined would be more complete.\n",
    "\n",
    "\n",
    "1. **Relative Importance of Neighbors** :  To take into account the fact that two countries can be neighbors and still have a big distance between them we decided to create a metric which would give importance to countries which are direct neighbors. We also wanted to make sure to give each neighbor the importance it is due. For example France has  multiple countries at its border. But that does not mean that each of these countries are of similar importance. That is why we weighted this metric by the size of the countries. Therefore a small neighboring country such as Luxemburg would have a smaller weight than Germany for example.  \n",
    "\n",
    "2. **Hop Distance** : This second metric accounts not only for direct neighbors but also for the smallest number of countries which would need to be traversed to connect any two countries in the world. \n",
    "\n",
    "3. **Flight Routes** : This last metric accounts for movement of populations between the different countries. The assumption is that the existence of flight routes is due to the fact that people exhibit a certain interest for the other country. The more often you visit a place, the more likely you are to be interested in what is going on there. \n",
    "\n",
    "\n",
    "These metrics are all constructed in the country distances noteboook in the GeoMetrics folder (**TODO : put link **). Refer to this noteboook for more detail on how the metrics were constructed. \n",
    "\n",
    "** Bird's Eye View Distance / Real Distance **\n",
    "\n",
    "Constructing this mapping was relatively straightforward. Using the position in latitude and longitude of the countries the distance between all countries in computed all the while being carefull with the extreme values of longitude. It is important to consider the shortest path as the earth is round. \n",
    "\n",
    "** TODO : load the pickle file and plot the heatmap as well as the distribution of values in KILOMETERS! (factor 105)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Hop Distance **\n",
    "\n",
    "\n",
    "For this metric as well as for the following we established an adjacency matrix of the connected countries in term of borders. It is important to note that Islands and certain continents are isolated which means that the resulting graph will not be fully connected. \n",
    "\n",
    "This will also be a usefull tool to create a neigborhood influence matrix.\n",
    "We can visualize the graph using networkx. \n",
    "\n",
    "**TODO : put the graph from Adrian's notebook with the nodes placed in the position of the countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the obtained graph in networkx we compute the shortest path between all pairs of nodes to obtain what we call the hop matrix between all countries. Countries which are not connected have a hop distance of infinity between them in the final dataframe. \n",
    "\n",
    "** TODO : insert the heatmap of the final hop matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO : put a screenshor of the map for a given country + LINK to the html with the map**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "** Relative Importance of Neighbors **\n",
    "\n",
    "The adjacency matrix established previously is then used to create a weighted adjacency matrix where the edges weighted by the size of the neighboring country over the sum of the sizes of all the neighbors. The graph is no longer an undirected graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO : put a screenshot of the map for a given country and link **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Flight Routes **\n",
    "\n",
    "Given a dataset of 59036 routes between 3209 airports on 531 airlines in the world as of January 2012. In addition the that we are able so associate all the Airports to their country thanks to a second dataset. **TODO : put the links towards the datasets**\n",
    "\n",
    "Once that was done, we associated all the routes with the departure and arrival countries. That way were able to determine for each country the proportion of flights to all other countries. \n",
    "\n",
    "In the same way as before the graph is a directed graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**TODO : put the heatmap**\n",
    "\n",
    "**TODO : put the graph with the nodes at the positions of the countries**\n",
    "\n",
    "**TODO : put a screenshor of the map for a given country**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO : put the link towards the interactive map for all the distance metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.4. Religions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Religion, like government, affects the way of thinking of the people. Religion bonds between countries will definitely have an impact on the awareness of events that happen in countries with the same religions.\n",
    "\n",
    "Here we can see the religion data that we were originally using in Milestone 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th colspan=\"16\" halign=\"left\">religion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Christianism</th>\n",
       "      <th>Judaism</th>\n",
       "      <th>Islam</th>\n",
       "      <th>Buddhism</th>\n",
       "      <th>Zoroastrian</th>\n",
       "      <th>Hindu</th>\n",
       "      <th>Sikh</th>\n",
       "      <th>Shinto</th>\n",
       "      <th>Baha'i</th>\n",
       "      <th>Taoism</th>\n",
       "      <th>Jain</th>\n",
       "      <th>Confucianism</th>\n",
       "      <th>Syncretic religions</th>\n",
       "      <th>Animist religions</th>\n",
       "      <th>Non-religious</th>\n",
       "      <th>Other religions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISO2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO</th>\n",
       "      <td>Angola</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010399</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075899</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150700</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>0.9070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674800</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>0.0041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name     religion                              \\\n",
       "                           Christianism Judaism     Islam  Buddhism   \n",
       "ISO2                                                                  \n",
       "AF             Afghanistan       0.0003     0.0  0.995600  0.000099   \n",
       "AO                  Angola       0.8912     0.0  0.010399  0.000099   \n",
       "AL                 Albania       0.2144     0.0  0.630000  0.000000   \n",
       "AD                 Andorra       0.9070     0.0  0.008999  0.000000   \n",
       "AE    United Arab Emirates       0.0714     0.0  0.674800  0.003500   \n",
       "\n",
       "                                                                              \\\n",
       "     Zoroastrian   Hindu      Sikh Shinto    Baha'i Taoism Jain Confucianism   \n",
       "ISO2                                                                           \n",
       "AF      0.000099  0.0003  0.000099    0.0  0.000099    0.0  0.0          0.0   \n",
       "AO      0.000000  0.0000  0.000000    0.0  0.000099    0.0  0.0          0.0   \n",
       "AL      0.000000  0.0000  0.000000    0.0  0.002200    0.0  0.0          0.0   \n",
       "AD      0.000000  0.0035  0.000000    0.0  0.000000    0.0  0.0          0.0   \n",
       "AE      0.000000  0.2225  0.000000    0.0  0.009999    0.0  0.0          0.0   \n",
       "\n",
       "                                                                          \n",
       "     Syncretic religions Animist religions Non-religious Other religions  \n",
       "ISO2                                                                      \n",
       "AF                   0.0          0.000099      0.002000          0.0014  \n",
       "AO                   0.0          0.075899      0.017899          0.0044  \n",
       "AL                   0.0          0.000000      0.150700          0.0027  \n",
       "AD                   0.0          0.000000      0.079600          0.0009  \n",
       "AE                   0.0          0.000000      0.013599          0.0041  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df_milestone2 = pd.read_pickle(\"./DataEnriching/Pickles for Milestone 3/final_rel_df.pickle\")\n",
    "rel_df_milestone2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there were too many countries for which the religion information was not complete. That is why we went back to the factbook which was more complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "From now on, we will explain how we took the data from the factbook dataset.\n",
    "\n",
    "We could extract the religions from Dataset 2, but we had to do some cleaning to have the desired format of the data. First we needed to know which where the religions that were in the dataset, so we created an array containing the unique names of the religions that appeared througouth each country. Once we know all the religions, we created the religions dataframe, containing the percentage of every religion in every country. Finally, we grouped the small religions in 10 broader categories of religions.\n",
    "\n",
    "As said, we start by creating the unique religions array. Here is a sample of part of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adventist',\n",
       " 'Animist',\n",
       " 'Armenian Apostolic',\n",
       " 'Assembly of God',\n",
       " 'Awakening Churches/Christian Revival',\n",
       " 'Badimo',\n",
       " \"Baha'i\",\n",
       " 'Baptist',\n",
       " 'Bektashi',\n",
       " 'Buddhism',\n",
       " 'Buddhist',\n",
       " 'Bukot nan Jesus',\n",
       " 'Calvinist',\n",
       " 'Cao Dai',\n",
       " 'Catholic',\n",
       " 'Christian',\n",
       " 'Christianity',\n",
       " 'Church of England',\n",
       " 'Church of Ireland',\n",
       " 'Church of Norway']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unique_religions[:20]\n",
    "['Adventist', 'Animist', 'Armenian Apostolic', 'Assembly of God', 'Awakening Churches/Christian Revival', 'Badimo',\n",
    " \"Baha'i\", 'Baptist', 'Bektashi', 'Buddhism', 'Buddhist', 'Bukot nan Jesus', 'Calvinist', 'Cao Dai', 'Catholic', 'Christian',\n",
    " 'Christianity','Church of England', 'Church of Ireland', 'Church of Norway']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all possible religions in one array, we will create the dataframe (rel_df), with all religions as columns, and the country as the index. The cell values will represent the percentage of the religion in the country.\n",
    "\n",
    "Some of the countries had bad formated data to be extracted (i.e. percentages given by ranges like 10-30%, some countries didn't have the percentages, etc). We manually added the rows of the countries that had issues. For the countries that didn't have percentages, we searched on Wikipedia for the percentages and we also added them manually.\n",
    "\n",
    "To create the rel_df dataframe, the rows were appended into an initial empty dataframe. The rows were created by looping through all unique_religions and checking if the country in particular had that religion. If it had it, we inserted the percentage. If it didn't have it, we inserted the value zero in that religion column.\n",
    "\n",
    "Here is what the rel_df looks like, after dropping the smallest religions (columns) that didn't have more than 10% in any country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Armenian Apostolic</th>\n",
       "      <th>Assembly of God</th>\n",
       "      <th>Awakening Churches/Christian Revival</th>\n",
       "      <th>Buddhism</th>\n",
       "      <th>Buddhist</th>\n",
       "      <th>Calvinist</th>\n",
       "      <th>Catholic</th>\n",
       "      <th>Christian</th>\n",
       "      <th>Church of Norway</th>\n",
       "      <th>Congregational Christian Church</th>\n",
       "      <th>...</th>\n",
       "      <th>none</th>\n",
       "      <th>none or other</th>\n",
       "      <th>other</th>\n",
       "      <th>other Christian</th>\n",
       "      <th>other and unspecified</th>\n",
       "      <th>other or none</th>\n",
       "      <th>other or unspecified</th>\n",
       "      <th>unaffiliated</th>\n",
       "      <th>unaffiliated or other</th>\n",
       "      <th>unspecified</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISO2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DZ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BW</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BJ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BI</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Armenian Apostolic  Assembly of God  \\\n",
       "ISO2                                        \n",
       "DZ                   0.0              0.0   \n",
       "AO                   0.0              0.0   \n",
       "BW                   0.0              0.0   \n",
       "BJ                   0.0              0.0   \n",
       "BI                   0.0              0.0   \n",
       "\n",
       "      Awakening Churches/Christian Revival  Buddhism  Buddhist  Calvinist  \\\n",
       "ISO2                                                                        \n",
       "DZ                                     0.0       0.0       0.0        0.0   \n",
       "AO                                     0.0       0.0       0.0        0.0   \n",
       "BW                                     0.0       0.0       0.0        0.0   \n",
       "BJ                                     0.0       0.0       0.0        0.0   \n",
       "BI                                     0.0       0.0       0.0        0.0   \n",
       "\n",
       "      Catholic  Christian  Church of Norway  Congregational Christian Church  \\\n",
       "ISO2                                                                           \n",
       "DZ       0.000      0.000               0.0                              0.0   \n",
       "AO       0.000      0.000               0.0                              0.0   \n",
       "BW       0.000      0.791               0.0                              0.0   \n",
       "BJ       0.255      0.000               0.0                              0.0   \n",
       "BI       0.621      0.000               0.0                              0.0   \n",
       "\n",
       "         ...        none  none or other  other  other Christian  \\\n",
       "ISO2     ...                                                      \n",
       "DZ       ...       0.000            0.0  0.010            0.000   \n",
       "AO       ...       0.123            0.0  0.086            0.000   \n",
       "BW       ...       0.152            0.0  0.014            0.000   \n",
       "BJ       ...       0.058            0.0  0.026            0.095   \n",
       "BI       ...       0.000            0.0  0.036            0.000   \n",
       "\n",
       "      other and unspecified  other or none  other or unspecified unaffiliated  \\\n",
       "ISO2                                                                            \n",
       "DZ                      0.0            0.0                   0.0          0.0   \n",
       "AO                      0.0            0.0                   0.0          0.0   \n",
       "BW                      0.0            0.0                   0.0          0.0   \n",
       "BJ                      0.0            0.0                   0.0          0.0   \n",
       "BI                      0.0            0.0                   0.0          0.0   \n",
       "\n",
       "      unaffiliated or other  unspecified  \n",
       "ISO2                                      \n",
       "DZ                      0.0        0.000  \n",
       "AO                      0.0        0.000  \n",
       "BW                      0.0        0.003  \n",
       "BJ                      0.0        0.000  \n",
       "BI                      0.0        0.079  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df = pd.read_pickle('./DataEnriching/rel_df.pickle')\n",
    "rel_df.set_index('ISO2', inplace=True)\n",
    "rel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping religions under broader categories\n",
    "We grouped the religions in broader categories by adding the percentages. We had to dropp some columns that didn't provide any information about the religious similarity between two countries (i.e unspecified, none or other, other, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are the broader categories that we came up with\n",
    "protestants = ['Calvinist', 'Church of Norway', 'Congregational Christian Church', 'Ekalesia Niue', 'Evangelical', \n",
    "               'Evangelical Lutheran', 'Evangelical Lutheran Church of Iceland', 'Evangelical or Protestant', 'Lutheran',\n",
    "               'Protestant', 'Protestant and other', 'Seventh-Day Adventist', 'non-Catholic Christians', 'Armenian Apostolic', \n",
    "               'Assembly of God', 'Christian', 'Kimbanguist', 'Mormon', 'Zionist Christian', 'nondenominational']\n",
    "               \n",
    "catholic = ['Awakening Churches/Christian Revival', 'Catholic', 'Roman Catholic', 'nominally Roman Catholic']\n",
    "orthodox = ['Eastern Orthodox', 'Ethiopian Orthodox', 'Greek Orthodox', 'Macedonian Orthodox', 'Orthodox', 'Orthodox Christian',\n",
    "                'Russian Orthodox', 'Serbian Orthodox']\n",
    "buddhism = ['Buddhism', 'Buddhist', 'Lamaistic Buddhist']\n",
    "hindu = ['Hindu', 'Indian- and Nepalese-influenced Hinduism']\n",
    "jewish = ['Jewish', 'Zionist', ]\n",
    "muslim = ['Muslim', 'Sunni Muslim']\n",
    "oriental = ['Shintoism', 'Taoist', 'mixture of Buddhist and Taoist']\n",
    "other = ['Vodoun', 'eclectic mixture of local religions', 'folk religion', 'indigenous beliefs']\n",
    "animist = ['animist', 'animist or no religion']\n",
    "atheist = ['atheist or agnostic', 'no religion', 'non-believer/agnostic', 'non-believers']\n",
    "unaffiliated = ['unaffiliated', 'unaffiliated or other']\n",
    "\n",
    "# Those religions will be dropped\n",
    "dropped_cols = ['Kempsville Presbyterian Church', 'none', 'none or other', 'other',\n",
    "                'other Christian', 'other and unspecified', 'other or none', 'other or unspecified', 'unspecified',\n",
    "                'atheist and agnostic']\n",
    "\n",
    "# Arrays needed to run next cell\n",
    "final_categories = [protestants, catholic, orthodox, buddhism, hindu, jewish, muslim, oriental, other, animist,\n",
    "                   atheist, unaffiliated]\n",
    "final_categories_names = ['protestants', 'catholic', 'orthodox', 'buddhism', 'hindu', 'jewish', 'muslim', \n",
    "                           'oriental', 'other', 'animist', 'atheist', 'unaffiliated']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that unifies the small religions to broader religion groups, and the resulting dataframe are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protestants</th>\n",
       "      <th>catholic</th>\n",
       "      <th>orthodox</th>\n",
       "      <th>buddhism</th>\n",
       "      <th>hindu</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>oriental</th>\n",
       "      <th>other</th>\n",
       "      <th>animist</th>\n",
       "      <th>atheist</th>\n",
       "      <th>unaffiliated</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ISO2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DZ</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO</th>\n",
       "      <td>0.381</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BW</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BJ</th>\n",
       "      <td>0.135</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BI</th>\n",
       "      <td>0.239</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      protestants  catholic  orthodox  buddhism  hindu  jewish  muslim  \\\n",
       "ISO2                                                                     \n",
       "DZ          0.000     0.000       0.0       0.0    0.0     0.0   0.990   \n",
       "AO          0.381     0.411       0.0       0.0    0.0     0.0   0.000   \n",
       "BW          0.791     0.000       0.0       0.0    0.0     0.0   0.000   \n",
       "BJ          0.135     0.255       0.0       0.0    0.0     0.0   0.277   \n",
       "BI          0.239     0.621       0.0       0.0    0.0     0.0   0.025   \n",
       "\n",
       "      oriental  other  animist  atheist  unaffiliated  \n",
       "ISO2                                                   \n",
       "DZ         0.0  0.000      0.0      0.0           0.0  \n",
       "AO         0.0  0.000      0.0      0.0           0.0  \n",
       "BW         0.0  0.000      0.0      0.0           0.0  \n",
       "BJ         0.0  0.116      0.0      0.0           0.0  \n",
       "BI         0.0  0.000      0.0      0.0           0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_categories_df(dataframe):\n",
    "    df = pd.DataFrame()\n",
    "    for category, category_name in zip(final_categories, final_categories_names):\n",
    "        df[category_name] = dataframe[category].sum(axis=1)\n",
    "    return df\n",
    "\n",
    "categorized_df = generate_categories_df(rel_df)\n",
    "categorized_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the distances, the euclidean dot product was applied using the following function, that returns the matrix with the distances between each pair of countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rel_distances = spatial.distance.squareform(spatial.distance.pdist(categorized_df,'euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DZ</th>\n",
       "      <th>AO</th>\n",
       "      <th>BW</th>\n",
       "      <th>BJ</th>\n",
       "      <th>BI</th>\n",
       "      <th>TD</th>\n",
       "      <th>CG</th>\n",
       "      <th>CD</th>\n",
       "      <th>CM</th>\n",
       "      <th>KM</th>\n",
       "      <th>...</th>\n",
       "      <th>UY</th>\n",
       "      <th>VE</th>\n",
       "      <th>AF</th>\n",
       "      <th>BD</th>\n",
       "      <th>BT</th>\n",
       "      <th>LK</th>\n",
       "      <th>IN</th>\n",
       "      <th>IO</th>\n",
       "      <th>MV</th>\n",
       "      <th>NP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DZ</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.137621</td>\n",
       "      <td>1.267194</td>\n",
       "      <td>0.777866</td>\n",
       "      <td>1.172172</td>\n",
       "      <td>0.476006</td>\n",
       "      <td>1.138065</td>\n",
       "      <td>1.064002</td>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.022361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.379166</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.140716</td>\n",
       "      <td>1.263309</td>\n",
       "      <td>1.144487</td>\n",
       "      <td>1.164662</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.250672</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO</th>\n",
       "      <td>1.137621</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.580535</td>\n",
       "      <td>0.418374</td>\n",
       "      <td>0.254733</td>\n",
       "      <td>0.664930</td>\n",
       "      <td>0.232011</td>\n",
       "      <td>0.156467</td>\n",
       "      <td>0.247931</td>\n",
       "      <td>1.121803</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657056</td>\n",
       "      <td>1.143718</td>\n",
       "      <td>1.057338</td>\n",
       "      <td>0.964330</td>\n",
       "      <td>0.886425</td>\n",
       "      <td>0.976756</td>\n",
       "      <td>0.560430</td>\n",
       "      <td>0.560430</td>\n",
       "      <td>0.987226</td>\n",
       "      <td>1.115069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BW</th>\n",
       "      <td>1.267194</td>\n",
       "      <td>0.580535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.765210</td>\n",
       "      <td>0.831246</td>\n",
       "      <td>0.879648</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.707871</td>\n",
       "      <td>0.687791</td>\n",
       "      <td>1.259556</td>\n",
       "      <td>...</td>\n",
       "      <td>1.231276</td>\n",
       "      <td>1.272670</td>\n",
       "      <td>1.195643</td>\n",
       "      <td>1.114240</td>\n",
       "      <td>1.071210</td>\n",
       "      <td>1.116598</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>0.791000</td>\n",
       "      <td>1.129041</td>\n",
       "      <td>1.246987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BJ</th>\n",
       "      <td>0.777866</td>\n",
       "      <td>0.418374</td>\n",
       "      <td>0.765210</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.470884</td>\n",
       "      <td>0.338941</td>\n",
       "      <td>0.418418</td>\n",
       "      <td>0.363366</td>\n",
       "      <td>0.232897</td>\n",
       "      <td>0.762309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774877</td>\n",
       "      <td>0.784287</td>\n",
       "      <td>0.695487</td>\n",
       "      <td>0.888417</td>\n",
       "      <td>0.781279</td>\n",
       "      <td>0.863744</td>\n",
       "      <td>0.416455</td>\n",
       "      <td>0.416455</td>\n",
       "      <td>0.903593</td>\n",
       "      <td>0.754105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BI</th>\n",
       "      <td>1.172172</td>\n",
       "      <td>0.254733</td>\n",
       "      <td>0.831246</td>\n",
       "      <td>0.470884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.714326</td>\n",
       "      <td>0.078549</td>\n",
       "      <td>0.154877</td>\n",
       "      <td>0.306165</td>\n",
       "      <td>1.153407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404360</td>\n",
       "      <td>1.177941</td>\n",
       "      <td>1.096685</td>\n",
       "      <td>1.029192</td>\n",
       "      <td>0.940524</td>\n",
       "      <td>1.040572</td>\n",
       "      <td>0.665873</td>\n",
       "      <td>0.665873</td>\n",
       "      <td>1.051521</td>\n",
       "      <td>1.150862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TD</th>\n",
       "      <td>0.476006</td>\n",
       "      <td>0.664930</td>\n",
       "      <td>0.879648</td>\n",
       "      <td>0.338941</td>\n",
       "      <td>0.714326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.679580</td>\n",
       "      <td>0.595317</td>\n",
       "      <td>0.436905</td>\n",
       "      <td>0.459959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.481991</td>\n",
       "      <td>0.407425</td>\n",
       "      <td>1.009283</td>\n",
       "      <td>0.888114</td>\n",
       "      <td>0.941826</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>0.634667</td>\n",
       "      <td>1.009011</td>\n",
       "      <td>0.454033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CG</th>\n",
       "      <td>1.138065</td>\n",
       "      <td>0.232011</td>\n",
       "      <td>0.810948</td>\n",
       "      <td>0.418418</td>\n",
       "      <td>0.078549</td>\n",
       "      <td>0.679580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142032</td>\n",
       "      <td>0.270889</td>\n",
       "      <td>1.119845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.443997</td>\n",
       "      <td>1.144062</td>\n",
       "      <td>1.059312</td>\n",
       "      <td>0.981134</td>\n",
       "      <td>0.893247</td>\n",
       "      <td>0.995275</td>\n",
       "      <td>0.588874</td>\n",
       "      <td>0.588874</td>\n",
       "      <td>1.005482</td>\n",
       "      <td>1.115895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>1.064002</td>\n",
       "      <td>0.156467</td>\n",
       "      <td>0.707871</td>\n",
       "      <td>0.363366</td>\n",
       "      <td>0.154877</td>\n",
       "      <td>0.595317</td>\n",
       "      <td>0.142032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172748</td>\n",
       "      <td>1.046327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547723</td>\n",
       "      <td>1.069864</td>\n",
       "      <td>0.987766</td>\n",
       "      <td>0.982777</td>\n",
       "      <td>0.889612</td>\n",
       "      <td>0.982495</td>\n",
       "      <td>0.591608</td>\n",
       "      <td>0.591608</td>\n",
       "      <td>1.001999</td>\n",
       "      <td>1.042351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>0.910891</td>\n",
       "      <td>0.247931</td>\n",
       "      <td>0.687791</td>\n",
       "      <td>0.232897</td>\n",
       "      <td>0.306165</td>\n",
       "      <td>0.436905</td>\n",
       "      <td>0.270889</td>\n",
       "      <td>0.172748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.894003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661545</td>\n",
       "      <td>0.916900</td>\n",
       "      <td>0.833598</td>\n",
       "      <td>0.937706</td>\n",
       "      <td>0.835379</td>\n",
       "      <td>0.921675</td>\n",
       "      <td>0.513266</td>\n",
       "      <td>0.513266</td>\n",
       "      <td>0.953356</td>\n",
       "      <td>0.888699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KM</th>\n",
       "      <td>0.022361</td>\n",
       "      <td>1.121803</td>\n",
       "      <td>1.259556</td>\n",
       "      <td>0.762309</td>\n",
       "      <td>1.153407</td>\n",
       "      <td>0.459959</td>\n",
       "      <td>1.119845</td>\n",
       "      <td>1.046327</td>\n",
       "      <td>0.894003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.358087</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>0.135355</td>\n",
       "      <td>1.255647</td>\n",
       "      <td>1.135804</td>\n",
       "      <td>1.157574</td>\n",
       "      <td>0.980204</td>\n",
       "      <td>0.980204</td>\n",
       "      <td>1.243286</td>\n",
       "      <td>0.025612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DZ        AO        BW        BJ        BI        TD        CG  \\\n",
       "DZ  0.000000  1.137621  1.267194  0.777866  1.172172  0.476006  1.138065   \n",
       "AO  1.137621  0.000000  0.580535  0.418374  0.254733  0.664930  0.232011   \n",
       "BW  1.267194  0.580535  0.000000  0.765210  0.831246  0.879648  0.810948   \n",
       "BJ  0.777866  0.418374  0.765210  0.000000  0.470884  0.338941  0.418418   \n",
       "BI  1.172172  0.254733  0.831246  0.470884  0.000000  0.714326  0.078549   \n",
       "TD  0.476006  0.664930  0.879648  0.338941  0.714326  0.000000  0.679580   \n",
       "CG  1.138065  0.232011  0.810948  0.418418  0.078549  0.679580  0.000000   \n",
       "CD  1.064002  0.156467  0.707871  0.363366  0.154877  0.595317  0.142032   \n",
       "CM  0.910891  0.247931  0.687791  0.232897  0.306165  0.436905  0.270889   \n",
       "KM  0.022361  1.121803  1.259556  0.762309  1.153407  0.459959  1.119845   \n",
       "\n",
       "          CD        CM        KM    ...           UY        VE        AF  \\\n",
       "DZ  1.064002  0.910891  0.022361    ...     1.379166  0.007000  0.140716   \n",
       "AO  0.156467  0.247931  1.121803    ...     0.657056  1.143718  1.057338   \n",
       "BW  0.707871  0.687791  1.259556    ...     1.231276  1.272670  1.195643   \n",
       "BJ  0.363366  0.232897  0.762309    ...     0.774877  0.784287  0.695487   \n",
       "BI  0.154877  0.306165  1.153407    ...     0.404360  1.177941  1.096685   \n",
       "TD  0.595317  0.436905  0.459959    ...     0.981408  0.481991  0.407425   \n",
       "CG  0.142032  0.270889  1.119845    ...     0.443997  1.144062  1.059312   \n",
       "CD  0.000000  0.172748  1.046327    ...     0.547723  1.069864  0.987766   \n",
       "CM  0.172748  0.000000  0.894003    ...     0.661545  0.916900  0.833598   \n",
       "KM  1.046327  0.894003  0.000000    ...     1.358087  0.026249  0.135355   \n",
       "\n",
       "          BD        BT        LK        IN        IO        MV        NP  \n",
       "DZ  1.263309  1.144487  1.164662  0.990000  0.990000  1.250672  0.026000  \n",
       "AO  0.964330  0.886425  0.976756  0.560430  0.560430  0.987226  1.115069  \n",
       "BW  1.114240  1.071210  1.116598  0.791000  0.791000  1.129041  1.246987  \n",
       "BJ  0.888417  0.781279  0.863744  0.416455  0.416455  0.903593  0.754105  \n",
       "BI  1.029192  0.940524  1.040572  0.665873  0.665873  1.051521  1.150862  \n",
       "TD  1.009283  0.888114  0.941826  0.634667  0.634667  1.009011  0.454033  \n",
       "CG  0.981134  0.893247  0.995275  0.588874  0.588874  1.005482  1.115895  \n",
       "CD  0.982777  0.889612  0.982495  0.591608  0.591608  1.001999  1.042351  \n",
       "CM  0.937706  0.835379  0.921675  0.513266  0.513266  0.953356  0.888699  \n",
       "KM  1.255647  1.135804  1.157574  0.980204  0.980204  1.243286  0.025612  \n",
       "\n",
       "[10 rows x 251 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting it to a dataframe\n",
    "rel_distance_df = pd.DataFrame(rel_distances, index=rel_df.index.tolist(), columns=rel_df.index.tolist())\n",
    "rel_distance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO : insert heatmap of the distances**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO INSERT MAP WITH ALL RELIGIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous cell we can see the visualization of the religion metric on a map. When clicking on countries which are majoritarely christian the distance metric does not account for the proximity between protestant, catholic and orthodox. That is why we decided to merge the three religions (protestants, catholics, orthodox) into one group (christianity). The results can be seen in the following map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO INSERT MAP WITH CHRISTIANS TOGETHER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that now two countries majoritarely christians are closer in the religion distance metric, meaning that we solved the problem.\n",
    "\n",
    "\n",
    "To compute the last map, we had to solve also the issues with the lack of data of some countries. In the categorized_df dataframe there are countries that have null values in every religion. This represents a big issue because when computing the distance between countries, these countries will have distance zero not for their religious proximity, but because we lacked the data. We managed to find the percentages of the main religions in most of the important countries by searching in Wikipedia. Here is an example of some manually inserted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We found the percentages on wikipedia by doing the search on google: percentages of main religions [country]\n",
    "data.set_value('Greenland', ('religion', 'christianity'), 0.96);\n",
    "data.set_value('Madagascar', ('religion', 'atheist'), 0.84);\n",
    "data.set_value('North Korea', ('religion', 'atheist'), 0.643);\n",
    "data.set_value('Palestine', ('religion', 'muslim'), 0.85);\n",
    "data.set_value('Palestine', ('religion', 'jewish'), 0.12);\n",
    "data.set_value('Sudan', ('religion', 'muslim'), 0.97);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.5. Population, Area, GDP, Internet users, population in poverty, unemployment rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countries can be characterized by general attributes such as population, size, gross domestic product (GDP), poverty line, internet users and so forth. These metrics are interesting because they are in direct link to the number of tweets in a conutry and can be used as normalizing factors. \n",
    "         \n",
    "As we announced previously, by using the factbook dataset for Milestone 3 we were able to extract more features than in Milestone 2. These features are straight forward to extract from Dataset 2 (see \"Data enriching.ipynb\"). From the data.pickle file we can extract them directly. The result is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>POP</th>\n",
       "      <th>area</th>\n",
       "      <th>gdp</th>\n",
       "      <th>gdp_capita</th>\n",
       "      <th>Internet users</th>\n",
       "      <th>pop_pov</th>\n",
       "      <th>unemployment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Aruba</th>\n",
       "      <td>113648.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2.516000e+09</td>\n",
       "      <td>25300.0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Afghanistan</th>\n",
       "      <td>33332025.0</td>\n",
       "      <td>652230.0</td>\n",
       "      <td>1.840000e+10</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2690000.0</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>20172332.0</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>9.194000e+10</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>2434000.0</td>\n",
       "      <td>0.405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anguilla</th>\n",
       "      <td>16752.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1.754000e+08</td>\n",
       "      <td>12200.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Åland Islands</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      POP       area           gdp gdp_capita Internet users  \\\n",
       "                                                                               \n",
       "name                                                                           \n",
       "Aruba            113648.0      180.0  2.516000e+09    25300.0        99000.0   \n",
       "Afghanistan    33332025.0   652230.0  1.840000e+10     2000.0      2690000.0   \n",
       "Angola         20172332.0  1246700.0  9.194000e+10     6800.0      2434000.0   \n",
       "Anguilla          16752.0       91.0  1.754000e+08    12200.0        12000.0   \n",
       "Åland Islands         NaN     1580.0           NaN        NaN            NaN   \n",
       "\n",
       "              pop_pov unemployment  \n",
       "                                    \n",
       "name                                \n",
       "Aruba             NaN        0.069  \n",
       "Afghanistan     0.358        0.350  \n",
       "Angola          0.405          NaN  \n",
       "Anguilla        0.230        0.080  \n",
       "Åland Islands     NaN          NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_features = pd.read_pickle('.\\DataEnriching\\data.pickle')\n",
    "cols = [('POP',''),('area',''),('gdp',''),('gdp_capita',''),('Internet users',''),('pop_pov',''),('unemployment','')]\n",
    "other_features = other_features[cols]\n",
    "other_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "##  3.6. Estimating Number of Active Tweeters \n",
    "\n",
    "As will be explained in the next portion of the notebook it is important to have a normalizing factor to account for differences in twitter activity between the different country. The ideal thing would have been to have the number of active tweeters per country. A second best would have been to simply have the number of tweeters per country. Unfortunately none of this is available to the public. That is why it was important to create our own estimation of these values to generate the model. \n",
    "\n",
    "We had at our disposal the number of tweets worldwide for 8 different events. We used this to compute the average number of tweets per country and used it as a baseline. We were careful to compute the average of tweets for a given country only using the data when there was no event in the given country. In clearer terms we did not take the number of tweets in France during Charlie Hebdo to compute the average number of tweets. We relied on the 7 other events. In the same fashion we did not consider the tweets for france during the event in Belgium as the countries are sufficiently close to generate larger than normal reactions. The inverse was also done for Belgium.  \n",
    "\n",
    "**TODO : load this data and print the average number of tweets in a week for a given country, show the difference for France with and without Charlie Hebdo to justify why**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "# 4. Constructing the Awareness Model \n",
    "\n",
    "## 4.1. Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Non Negative Matrix Factorization\n",
    "\n",
    "Expliquer pourquoi ca n'a pas fonctionné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Graph Construction and Graph Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Regression Model To Predict Reaction Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "# 4. Critical Assessment and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
