{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3 - Report\n",
    "------\n",
    "In this notebook we are going to review everything that was done in the project following Milestone 2. The focus at this point of the project was placed on constructing the awareness model and the final datastory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import folium\n",
    "import branca\n",
    "import jenkspy\n",
    "import pickle\n",
    "import unicodedata\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Abstract\n",
    "\n",
    "*What's the motivation behind your project? A 150 word description of the project idea, goals, dataset used. What story you would like to tell and why?*\n",
    "\n",
    "Major events happen on a regular basis all around the world, some involving high number of casualties but the resulting reaction on the international scale is often far from proportional. Most of the time the largest reaction comes from the place where the incident occurred or places which are closeby. The objective would be to create an awareness map, and determine why people react to an event. From that we would attempt to define an awareness metric. We want to see how factors other than physical proximity come into play such as country, culture, language, religion. With this we could determine which country has the highest level of international awareness. The project would require the Twitter API to acquire hashtag specific tweets with geolocation and therefore measure the awareness and reactions of different communities to a given event. GDELT would be used to recover standardised information regarding different events.\n",
    "____\n",
    "____\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Recapitulation of Milestone 2\n",
    "\n",
    "To recap what was done in the previous milestone, here we present a brief summary of the previous notebook which can be found here **(TODO : mettre le lien)**. \n",
    "\n",
    "____\n",
    "\n",
    "## 1.1 Tweet Acquisition\n",
    "A lot of time was spent acquiring the Tweets for two main reasons : \n",
    "- The Twitter dump did not contain the geolocations of the tweets or the users. \n",
    "- The Twitter API does not permit the recovery of tweets which are over 1 week old when searching for tweets with a given hashtag around a specific date. \n",
    "\n",
    "That is why a significant amount of time was put into recovering the tweets through webscraping using phantom js with random scrolling time and random breaks to avoid being blocked by Twitter.\n",
    "\n",
    "The tweets were acquired based on their hashtags, all the while making sure to have a wide range of hashtags in different languages. \n",
    "____\n",
    "\n",
    "## 1.2. Tweet Geolocalisation\n",
    "\n",
    "Once the tweets were recovered we only kept those for which we had either the geolocalisation of the tweets itself or of the user. As the locations are manually input, they are not standardized and the corresponding location needed to be determined. \n",
    "\n",
    "The first step was therefore to format the strings by removing all special characters as setting everything to lower case for example.  Afterwards, we created multiple mappings which were used in the order presented as they represent the confidence in the given method : \n",
    "- A country mapper which uses multiple variations of the country name (different spellings and languages) to determine the country it corresponds to with the given ISO2 code\n",
    "- A capital mapper which maps the capital of a country to the ISO2 code\n",
    "- A first city mapper where duplicates were removed as there are multiple cities in the world with the same name (example : Torronto in Canada, the US and Australia). \n",
    "- A final city mapper with all the cities of all the countries in the world using the database provided here **(TODO : mettre le lien)**\n",
    "\n",
    "## 1.3. Visualization of the Reaction For An Event\n",
    "\n",
    "We then observed for one of the selected events the number of related tweets on a Chloropleth map. This helped us note certain issues in the mappings (high number of tweets in Antarctica for example). \n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "## 1.4. Enriching the Data \n",
    "\n",
    "To create our awareness model we wanted to recover information which could be used to determine a sort of distance between the different countries, that is why we recovered for all countries : \n",
    "- population\n",
    "- area\n",
    "- GDP\n",
    "- languages\n",
    "- religions\n",
    "- government types\n",
    "- border countries\n",
    "- latitude and longitude\n",
    "\n",
    "____\n",
    "____\n",
    "____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "# 2. Improving the Mappings\n",
    "\n",
    "One main issue with the mapping up until now is that there were redundancies which were not correctly handled. At the time of Milestone 2 we would just go through the complete mapping sequentially and stop at the first match. As there were duplicates there was no guarantee that the city found was the most coherent. That is why we corrected the mapping to take into account the population of the different cities which was also provided in the GeoNames database http://download.geonames.org/export/dump/. Therefore when there are multiple cities with the same name in different countries, we only keep the city with the largest population as it would be the most probable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also replaced our intermediate city mapping with a mapping containing the top 20'000 cities in the world (and therefore the most probable). With appoximately 200 countries this corresponds to around 100 cities per country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Creating the Awareness Model\n",
    "\n",
    "To create our model we decided to construct a graph linking all countries where the weights of the segments would represent the proximity between countries in terms of awareness to major events. \n",
    "\n",
    "For that we used the dataset containing all the information regarding the countries and looked to give numeric values to all the different categories mentioned previously and a few new ones: \n",
    "\n",
    "1. Languages\n",
    "2. Governments \n",
    "3. Distances between countries :\n",
    "    - Birds eye view distances \n",
    "    - Hop matrix : the number of countries which separate two given countries (**TODO : noter quil y a le souci des distances a traverser au sein des pays qui n'est pas pris en compte, exemple de la Finlande a la Chine qui passe uniquement par la russie**). \n",
    "    - Normalized Adj matrix : a matrix which gives the neighboring countries with a normalizing factor to account for multiple countries on the border\n",
    "    - Flight routes between countries\n",
    "4. Religion\n",
    "5. Population, Area, GDP\n",
    "\n",
    "\n",
    "What needed to be taken into account here is that we have many variables which are categoric. Therefore we needed to find a way to attribute numeric values in order to construct the final graph.\n",
    "\n",
    "Remark : most of the information was extracted from the CIA factbook as it is a complete and realiable source. \n",
    "\n",
    "**TODO : voir si le fait que le pays soit très grand avec une grande population qui peut diminuer l'intérêt par rapport à ce qui se passe ailleurs dans le monde**\n",
    "\n",
    "____\n",
    "\n",
    "## 3.1. Languages\n",
    "\n",
    "Languages are representative of culture and most of the time, countries which speak the same language have a given proximity. That is why this metric was used to create the graph. \n",
    "\n",
    "Two main possibilities presented themselves :\n",
    "- binary : if two countries have the same official language then they are linked\n",
    "- more informed : some languages are similar in the sense of understanding the other language, learning it, etc. That is why we wanted to take into account Linguistic distances. Unfortunately this is a current research topic and there is no database which gives the Linguistic distances between all the official languages of all countries. Certain databases exist linking English to other languages but this is not sufficient for our application. That is why we decided to use another metric, albeit more abstact, which is to say the phylogenetic trees linking languages together. \n",
    "\n",
    "\n",
    "Using the phylogenetic trees taken here (TODO insert nice link) http://glottolog.org/glottolog/family, we were able to construct a distance metric and compute the distances between all languages as can be seen below. The notebook handling this can be found here (TODO : mettre le lien du notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO METTRE LA MATRICE DISTANCE ENTRE LES LANGUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this language distance matrix we were able to compute a standardized distance between all countries. \n",
    "\n",
    "The idea is the following :\n",
    "- if countries have an official language in common, set the distance to 0\n",
    "- else get the distances between the official languages and compute the average of the non infinite distances. \n",
    "- else set the distance to inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO METTRE LA MATRICE DISTANCE ENTRE LES PAYS SELON LA LANGUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The issue with this type of distance is that it takes discrete values which don't account for the actual distance between the different languages in terms of comprehension, facility to learn the other language etc.. For example the distance between French and a dialect ....\n",
    "**TODO : afficher deux valeurs de distance similaires mais qui ne sont pas représentatifs**\n",
    "\n",
    "Results more representative of the reality of the situation could have been obtained had we had not only the phylogenetic links between the languages but the moment that the a new language appeared from a mother language. Incoroporating this time component would have given a more precise approximation, assuming that languages evolve at similar rates and that once the new language has emerged that there is minimal contact / influence from the mother or any sister languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : METTRE LA MATRICE STANDARDIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.2. Governments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type of government is also a good representative of the people's perception to worldwide events. People of different countries with the same government type will be influenced in a similar way. \n",
    "\n",
    "After getting the list of all the government types (see Country data gathering.ipynb for more details on how we got them) we have to convert them to a numeric scale with a meaning.\n",
    "\n",
    "First, we start by dividing all the government types in three groups and assigning them numerical values -1, 0 and 1. These are the resulting groups:\n",
    "- Group 1:\n",
    "    - 'parliamentary democracy'\n",
    "    - 'parliamentary republic'\n",
    "    - 'federal republic'\n",
    "    - 'federation of monarchies'\n",
    "    - 'semi-presidential republic'\n",
    "    - 'semi-presidential federation'\n",
    "- Group 2: \n",
    "    - 'non-self-governing overseas territory'\n",
    "    - 'in transition'\n",
    "    - 'unknown'\n",
    "- Group 3: \n",
    "    - 'presidential republic'\n",
    "    - 'presidential democracy'\n",
    "    - 'monarchy'\n",
    "    - 'theocratic republic'\n",
    "    - 'communist state'\n",
    "    - 'absolute monarchy'\n",
    "\n",
    "As our criteria to group the government types, we used the variable of the power that the leaders of the government have. Coutries where the leader has a lot of power go in group 3 and will be assigned to the value of 1, the others in group 1 and they will be assigned the value -1. For the non well defined government types, we placed them at the center of the scale with the value of 0.\n",
    "\n",
    "Here is the actual implementation (full code on Dataframes.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./DataEnriching/data.pickle')\n",
    "gov_type_array = [['parliamentary democracy', 'parliamentary republic', 'federal republic', 'federation of monarchies', \\\n",
    "                  'semi-presidential republic', 'semi-presidential federation'], \n",
    "                  ['non-self-governing overseas territory', 'in transition', 'unknown'], \n",
    "                  ['presidential republic', 'presidential democracy', 'monarchy', 'theocratic republic', 'communist state',\\\n",
    "                  'absolute monarchy']]\n",
    "mapping_gov_type=dict()\n",
    "for i, gov_group in enumerate(gov_type_array):\n",
    "    for gov in gov_group:\n",
    "        if i==0:\n",
    "            mapping_gov_type.update({gov: -1})\n",
    "        elif i==1:\n",
    "            mapping_gov_type.update({gov: 0})\n",
    "        else:\n",
    "            mapping_gov_type.update({gov: 1})\n",
    "\n",
    "# Mapping gov_type values to their numerical value (1, 0, -1)\n",
    "data['gov_type_num'] = data.gov_type.map(mapping_gov_type)\n",
    "data[['gov_type', 'gov_type_num']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.3. Distances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.4. Religions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Religion, like government, affects the way of thinking of the people. Religion bonds between countries will definitely have an impact on the awareness of events that happen in countries with the same religions.\n",
    "\n",
    "By reading the raw data excel file, we directly had the data in the format that is needed so we just selected the neccessary columns. Each column contains the percentage of adherents of the religion in each country.\n",
    "\n",
    "Here is the dataframe with all the selected data (full code on Dataframes.ipynb):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df = pd.read_pickle(\"./DataEnriching/Pickles for Milestone 3/final_rel_df.pickle\")\n",
    "rel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there were too many countries for which the religion information was not complete. That is why we went back to the factbook which was more complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_df[pd.isnull(rel_df).any(axis=1)]\n",
    "#print(\"Number of countries without religion {}\".format())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO INSERT MAP WITH ALL RELIGIONS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the visualization of the religion metric on a map. When clicking on countries which are majoritarely christian the distance metric does not account for the proximity between protestant, catholic and orthodox. That is why we decided to merge the three religions into one group (christian). The results can be seen in the following map. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO INSERT MAP WITH CHRISTIANS TOGETHER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.5. Population, Area, GDP "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This data is also straight forward to extract. From the data.pickle file we can extract it directly. The result is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_POP_gdp_df = pd.read_pickle('.\\DataEnriching\\Pickles for Milestone 3\\\\area_POP_gdp_df.pickle')\n",
    "area_POP_gdp_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "\n",
    "## 3.6. Constructing the Awareness Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "____\n",
    "____\n",
    "\n",
    "# 4. Predictions Using the Awareness Model and Graph Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
