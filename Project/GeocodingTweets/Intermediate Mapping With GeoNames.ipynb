{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we take some of the functions implemented in the Constructing the Mappings Notebook in order to process the \"cities15000.txt\" file provided by the GeoNames database. This textfile contains the largest cities in the world which therefore would be the most likely. That is why we replaced our intermediate city mapping by this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geocoder, geopy\n",
    "import time\n",
    "import unicodedata\n",
    "import pickle\n",
    "import contextlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the helper functions from the Constructing the Mappings Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/8694815/removing-accent-and-special-characters\n",
    "def remove_accents(data):\n",
    "    if data is None:\n",
    "        return None\n",
    "    else :\n",
    "        clean = ''.join(x.lower().strip() for x in unicodedata.normalize('NFKD', data) if \\\n",
    "                unicodedata.category(x)[0] == 'L').lower()\n",
    "        return clean\n",
    "\n",
    "def string_formatting(string):\n",
    "    string = string.replace(\"-\", \" \").replace(\" \", \",\").split(\",\")\n",
    "    formatted_string = [remove_accents(x.lower()) for x in string]\n",
    "    return string,formatted_string\n",
    "\n",
    "def clean_sublist(x):\n",
    "    return list(set(filter(None, np.hstack(x))))\n",
    "\n",
    "def remove_accents_in_sublist(l):\n",
    "    return list(map(lambda x:remove_accents(x.lower()),l))\n",
    "    \n",
    "def remove_accents_in_list(lists):\n",
    "    return list(map(lambda x:remove_accents_in_sublist(x),lists))\n",
    "\n",
    "def clean_and_remove_accents_in_list(lists):\n",
    "    return list(map(lambda x:clean_sublist(remove_accents_in_sublist(x)),lists))\n",
    "\n",
    "def convert_df_to_dict(df, do_prints = False):\n",
    "    \n",
    "    # Converting the dataframe values to list and cleaning them\n",
    "    t = time.time()\n",
    "    df_list = list(map(lambda x:clean_sublist(x),df.values.tolist()))\n",
    "    if do_prints : print(\"Converting to list :\", time.time()-t)\n",
    "\n",
    "    # Removing all the accents from the elements in the list\n",
    "    t = time.time()\n",
    "    df_variants = clean_and_remove_accents_in_list(df_list)\n",
    "    if do_prints : print(\"Getting variants :\", time.time()-t)\n",
    "    \n",
    "    # Combining the lists with original spellings and without accents\n",
    "    t = time.time()\n",
    "    df_all =  list(map(lambda x: list(set(df_list[x] + df_variants[x])),range(len(df))))\n",
    "    if do_prints : print(\"Combining Lists :\", time.time()-t)\n",
    "        \n",
    "    # Getting all the keys\n",
    "    t = time.time()\n",
    "    keys = list(map(lambda x: [df.index[x]]*(len(df_all[x])),range(len(df_all))))\n",
    "    if do_prints : print(\"Getting all keys :\", time.time()-t)\n",
    "      \n",
    "    \n",
    "    # Creating the dataframe\n",
    "    t = time.time()\n",
    "    mapping = pd.DataFrame(index = sum(df_all, []),data=sum(keys, []))\n",
    "    #mapping = dict(zip(sum(df_all, []),sum(keys, [])))\n",
    "    if do_prints : print(\"Converting to dict :\", time.time()-t)\n",
    "        \n",
    "    return mapping\n",
    "\n",
    "def extract_alternate_names(x):\n",
    "    try:\n",
    "        out = x.split(\",\")\n",
    "        return out\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a variant of the process dataframe function so that it better correspond to the new text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(full_filename, do_prints = False):\n",
    "    # Load the text file as a csv\n",
    "    \n",
    "    dtypes = [int,str, str,str,float,float,str,str,\\\n",
    "             str,str,str,str, str,str,int,str,\\\n",
    "             str,str,str]\n",
    "    \n",
    "    columns = [\"geonameid\",\"name\", \"asciiname\",\"alternatenames\",\\\n",
    "               \"latitude\",\"longitude\",\"feature class\",\"feature code\",\\\n",
    "               \"country code\",\"cc2\",\"admin1 code\",\"admin2 code\",\\\n",
    "               \"admin3 code\",\"admin4 code\",\"population\",\"elevation\",\\\n",
    "               \"dem\",\"timezone\",\"modification date\"]\n",
    "    \n",
    "    cities = pd.read_csv(full_filename, sep = \"\\t\", header=None, names=columns, dtype = dict(zip(columns,dtypes)))\n",
    "        \n",
    "    if do_prints: print(\"Loaded\")\n",
    "    \n",
    "    # Keep only the relevant columns\n",
    "    cities = cities[[\"name\",\"asciiname\", \"alternatenames\", \"country code\",\"population\"]]\n",
    "    \n",
    "    # Format the given columns\n",
    "    cities[\"name\"] = cities[\"name\"].apply(lambda x: extract_alternate_names(x))\n",
    "    cities[\"asciiname\"] = cities[\"asciiname\"].apply(lambda x: extract_alternate_names(x))\n",
    "    cities[\"alternatenames\"] = cities[\"alternatenames\"].astype(\"object\")\n",
    "    cities[\"alternatenames\"] = cities[\"alternatenames\"].apply(lambda x: extract_alternate_names(x))\n",
    "    \n",
    "    \n",
    "    # Store the population and cities dataframes\n",
    "    if do_prints: print(\"Processed\")\n",
    "    pop = cities.copy()\n",
    "    \n",
    "    pop.drop([\"country code\"], axis = 1, inplace = True)\n",
    "    cities.drop([\"population\"], axis = 1, inplace = True)\n",
    "    \n",
    "    cities.set_index(\"country code\", inplace = True)\n",
    "    pop.set_index(\"population\", inplace = True)\n",
    "    \n",
    "    if do_prints: print(\"Indexed\")\n",
    "    \n",
    "    return cities, pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_city, interm_pop = process_dataframe(os.path.join(os.getcwd(), \"Mapping Files\",\"cities15000.txt\"), do_prints = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>alternatenames</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>[les Escaldes]</td>\n",
       "      <td>[les Escaldes]</td>\n",
       "      <td>[Ehskal'des-Ehndzhordani, Escaldes, Escaldes-E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AD</th>\n",
       "      <td>[Andorra la Vella]</td>\n",
       "      <td>[Andorra la Vella]</td>\n",
       "      <td>[ALV, Ando-la-Vyey, Andora, Andora la Vela, An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Umm al Qaywayn]</td>\n",
       "      <td>[Umm al Qaywayn]</td>\n",
       "      <td>[Oumm al Qaiwain, Oumm al Qaïwaïn, Um al Kawai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Ras al-Khaimah]</td>\n",
       "      <td>[Ras al-Khaimah]</td>\n",
       "      <td>[Julfa, Khaimah, RKT, Ra's al Khaymah, Ra's al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Khawr Fakkān]</td>\n",
       "      <td>[Khawr Fakkan]</td>\n",
       "      <td>[Fakkan, Fakkān, Khawr Fakkan, Khawr Fakkān, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Dubai]</td>\n",
       "      <td>[Dubai]</td>\n",
       "      <td>[DXB, Dabei, Dibai, Dibay, Doubayi, Dubae, Dub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Dibba Al-Fujairah]</td>\n",
       "      <td>[Dibba Al-Fujairah]</td>\n",
       "      <td>[Al-Fujairah, BYB, Dibba Al-Fujairah, dba alfj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Dibba Al-Hisn]</td>\n",
       "      <td>[Dibba Al-Hisn]</td>\n",
       "      <td>[BYB, Daba, Daba al-Hisn, Dabā, Dabā al-Ḥiṣn, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Sharjah]</td>\n",
       "      <td>[Sharjah]</td>\n",
       "      <td>[Al Sharjah, Ash 'Mariqah, Ash Shariqa, Ash Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Ar Ruways]</td>\n",
       "      <td>[Ar Ruways]</td>\n",
       "      <td>[Ar Ru'ays, Ar Ruways, Ar Ru’ays, Ar-Ruvais, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Al Fujayrah]</td>\n",
       "      <td>[Al Fujayrah]</td>\n",
       "      <td>[Al Fujayrah, Al-Fudjayra, Al-Fujayrah' emiraa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Al Ain]</td>\n",
       "      <td>[Al Ain]</td>\n",
       "      <td>[AAN, Ainas, Al Ain, Al Ajn, Al Ayn, Al `Ayn, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Ajman]</td>\n",
       "      <td>[Ajman]</td>\n",
       "      <td>[Ajman, Al Ajman, QAJ, Ujman, ʿjman, عجمان]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Adh Dhayd]</td>\n",
       "      <td>[Adh Dhayd]</td>\n",
       "      <td>[Adh Dhaid, Adh Dhayd, Al Daid, Al-Dhayd, Dayd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>[Abu Dhabi]</td>\n",
       "      <td>[Abu Dhabi]</td>\n",
       "      <td>[A-pu-that-pi, AEbu Saby, AUH, Aboe Dhabi, Abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>[Zaranj]</td>\n",
       "      <td>[Zaranj]</td>\n",
       "      <td>[Sarandsch, ZAJ, Zaranas, Zarandj, Zarandz, Za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>[Taloqan]</td>\n",
       "      <td>[Taloqan]</td>\n",
       "      <td>[Khanabad, TQN, Taikhan, Taleqan, Talikan, Tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>[Shīnḏanḏ]</td>\n",
       "      <td>[Shindand]</td>\n",
       "      <td>[Asfazar, Asfazār, OAH, Sabzavar, Sabzavār, Sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>[Shibirghān]</td>\n",
       "      <td>[Shibirghan]</td>\n",
       "      <td>[Markaz-e Wilayat-e Shibirghan, Markaz-e Wilāy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AF</th>\n",
       "      <td>[Shahrak]</td>\n",
       "      <td>[Shahrak]</td>\n",
       "      <td>[Bati Dara, Kala Shaharak, Kala Shahrak, Kala ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name            asciiname  \\\n",
       "country code                                             \n",
       "AD                 [les Escaldes]       [les Escaldes]   \n",
       "AD             [Andorra la Vella]   [Andorra la Vella]   \n",
       "AE               [Umm al Qaywayn]     [Umm al Qaywayn]   \n",
       "AE               [Ras al-Khaimah]     [Ras al-Khaimah]   \n",
       "AE                 [Khawr Fakkān]       [Khawr Fakkan]   \n",
       "AE                        [Dubai]              [Dubai]   \n",
       "AE            [Dibba Al-Fujairah]  [Dibba Al-Fujairah]   \n",
       "AE                [Dibba Al-Hisn]      [Dibba Al-Hisn]   \n",
       "AE                      [Sharjah]            [Sharjah]   \n",
       "AE                    [Ar Ruways]          [Ar Ruways]   \n",
       "AE                  [Al Fujayrah]        [Al Fujayrah]   \n",
       "AE                       [Al Ain]             [Al Ain]   \n",
       "AE                        [Ajman]              [Ajman]   \n",
       "AE                    [Adh Dhayd]          [Adh Dhayd]   \n",
       "AE                    [Abu Dhabi]          [Abu Dhabi]   \n",
       "AF                       [Zaranj]             [Zaranj]   \n",
       "AF                      [Taloqan]            [Taloqan]   \n",
       "AF                     [Shīnḏanḏ]           [Shindand]   \n",
       "AF                   [Shibirghān]         [Shibirghan]   \n",
       "AF                      [Shahrak]            [Shahrak]   \n",
       "\n",
       "                                                 alternatenames  \n",
       "country code                                                     \n",
       "AD            [Ehskal'des-Ehndzhordani, Escaldes, Escaldes-E...  \n",
       "AD            [ALV, Ando-la-Vyey, Andora, Andora la Vela, An...  \n",
       "AE            [Oumm al Qaiwain, Oumm al Qaïwaïn, Um al Kawai...  \n",
       "AE            [Julfa, Khaimah, RKT, Ra's al Khaymah, Ra's al...  \n",
       "AE            [Fakkan, Fakkān, Khawr Fakkan, Khawr Fakkān, K...  \n",
       "AE            [DXB, Dabei, Dibai, Dibay, Doubayi, Dubae, Dub...  \n",
       "AE            [Al-Fujairah, BYB, Dibba Al-Fujairah, dba alfj...  \n",
       "AE            [BYB, Daba, Daba al-Hisn, Dabā, Dabā al-Ḥiṣn, ...  \n",
       "AE            [Al Sharjah, Ash 'Mariqah, Ash Shariqa, Ash Sh...  \n",
       "AE            [Ar Ru'ays, Ar Ruways, Ar Ru’ays, Ar-Ruvais, R...  \n",
       "AE            [Al Fujayrah, Al-Fudjayra, Al-Fujayrah' emiraa...  \n",
       "AE            [AAN, Ainas, Al Ain, Al Ajn, Al Ayn, Al `Ayn, ...  \n",
       "AE                  [Ajman, Al Ajman, QAJ, Ujman, ʿjman, عجمان]  \n",
       "AE            [Adh Dhaid, Adh Dhayd, Al Daid, Al-Dhayd, Dayd...  \n",
       "AE            [A-pu-that-pi, AEbu Saby, AUH, Aboe Dhabi, Abo...  \n",
       "AF            [Sarandsch, ZAJ, Zaranas, Zarandj, Zarandz, Za...  \n",
       "AF            [Khanabad, TQN, Taikhan, Taleqan, Talikan, Tal...  \n",
       "AF            [Asfazar, Asfazār, OAH, Sabzavar, Sabzavār, Sa...  \n",
       "AF            [Markaz-e Wilayat-e Shibirghan, Markaz-e Wilāy...  \n",
       "AF            [Bati Dara, Kala Shaharak, Kala Shahrak, Kala ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interm_city.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_city_df = convert_df_to_dict(interm_city, do_prints = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_pop_df = convert_df_to_dict(interm_pop, do_prints = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open(os.path.join(os.getcwd(), \"cities15000.pickle\"), 'wb')\n",
    "pickle.dump(interm_city_dict, pickle_file, protocol=4)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = open(os.path.join(os.getcwd(), \"cities15000_pop.pickle\"), 'wb')\n",
    "pickle.dump(interm_pop_dict, pickle_file, protocol=4)\n",
    "pickle_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_pop_dict = {}\n",
    "full_city_mappings = {}\n",
    "full_pop_mappings = {}\n",
    "n_empty_pop = 0\n",
    "n_cities_tot = 0\n",
    "\n",
    "\n",
    "# Adding conditionnally the pickle content\n",
    "for city_name, country_code in city_pkl.items():\n",
    "    n_cities_tot += 1\n",
    "    if pop_pkl.get(city_name) == None :\n",
    "        pop_pkl.update({city_name : 0 })\n",
    "        empty_pop_dict.update({city_name : 'Pas de data' })\n",
    "        n_empty_pop +=1\n",
    "\n",
    "    if (full_city_mappings.get(city_name) == None):\n",
    "        full_city_mappings.update({city_name : country_code })\n",
    "        full_pop_mappings.update({city_name : pop_pkl[city_name] })\n",
    "    else : \n",
    "        if (pop_pkl[city_name] > full_pop_mappings[city_name]) :\n",
    "            full_city_mappings.update({city_name : country_code })\n",
    "            full_pop_mappings.update({city_name : pop_pkl[city_name] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ZA'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_city_mappings['Paris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "can not merge DataFrame with instance of type <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b615ee371811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterm_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterm_city_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterm_pop_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/ADA/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     51\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/ADA/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m    529\u001b[0m             raise ValueError(\n\u001b[1;32m    530\u001b[0m                 \u001b[0;34m'can not merge DataFrame with instance of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 'type {0}'.format(type(left)))\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: can not merge DataFrame with instance of type <class 'dict'>"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_pop_dict = {}\n",
    "full_city_mappings = {}\n",
    "full_pop_mappings = {}\n",
    "n_empty_pop = 0\n",
    "n_cities_tot = 0\n",
    "\n",
    "citylist = list(interm_city_df.index)\n",
    "# Adding conditionnally the pickle content\n",
    "for i in range(len(interm_city_df)):\n",
    "    city_name = citylist[i]\n",
    "    country_code = interm_city_df[0].iloc[i]\n",
    "    n_cities_tot += 1\n",
    "    #if pop_pkl.get(city_name) == None :\n",
    "    #    pop_pkl.update({city_name : 0 })\n",
    "    #    empty_pop_dict.update({city_name : 'Pas de data' })\n",
    "    #    n_empty_pop +=1\n",
    "\n",
    "    if (full_city_mappings.get(city_name) == None):\n",
    "        full_city_mappings.update({city_name : country_code })\n",
    "        full_pop_mappings.update({city_name : interm_pop_df[0].iloc[i] })\n",
    "    else : \n",
    "        if (interm_pop_df[0].iloc[i] > full_pop_mappings[city_name]) :\n",
    "            full_city_mappings.update({city_name : country_code })\n",
    "            full_pop_mappings.update({city_name : interm_pop_df[0].iloc[i] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(full_city_mappings,open(os.path.join('countries15000_with_pop.json'),'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ADA]",
   "language": "python",
   "name": "conda-env-ADA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
